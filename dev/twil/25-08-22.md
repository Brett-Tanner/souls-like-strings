---
date: "2025-08-22T18:43:11+09:00"
draft: false
title: "TWIL August 22nd 2025"
tags: [dev, TWIL]
layout: _post.html
---

- Don't forget an element is in the page twice, especially if it has an ID and you're trying to attach a click handler using that ID
  - can lead to long, hair tearing debug sessions followed by a lightbulb moment when you call `click()` directly on the element in the browser console
  - I just could not wrap my head around how the inspect panel could show an event attached to it, with the correct code in that event when expanded, but then not do anything when clicked
  - I guess for elements with IDs the inspect panel just shows the event as attached to both, but the actual browser definitely doesn't behave like that
  - might be a bit of a bug actually, but I guess no one noticed it because they're not dumb enough to have two elements with the same ID then try to attach a click listener using that ID
- If your favicon doesn't use an absolute path, it can work on the homepage but nowhere else

## Meetups

Tokyo Rubyist finally happened again! They always say it would happen more frequently if more people gave talks and I think I feel confident enough to do that at this point, so I'll try and think of something. Unfortunately I have less to do with Rails these days but the list endpoint optimisation I did might be an interesting talk, a lot of different things I could dig into.

The first talk was on the differences between Rails 1.0 & 8.0. It was a bit rough around the edges but still interesting, the guy giving it is presenting at Rails World in two weeks so I think he did this as a practice run before it was fully ready lol. Also he was a fellow Neovim user, with a very similar setup. Some of the main takeways were that the Rails codebase is now **7 times** larger, from 50 000 LOC to 350 000, and that even fairly simple methods which existed back then like `blank?` are a lot more complex now after more edge-cases have been discovered.

The second talk was by a guy from Rakuten who'd done some scientific-ish research on having LLMs review PRs, which I don't think is something we've even looked into. He had a bunch of LLMs review the same PR 5 times each with the same prompt, then scored them for each issue correctly identified (1-3 based on severity) and subtracted points for each fake issue/fix that would've broken something (-1 to -3 based on severity). The main takeaway was that if you're going to do it, GPT-5 is definitely the most useful option (caveat is that he used Rails 8, which might not/barely be represented in training data for older models), but I'm not convinced even that is a good idea.

One issue is the variance in results, he ran each prompt 5 times on the same PR with the same model and saw a reasonably large variance in results between runs with the same model. Running an LLM on a PR's worth of tokens (plus context since he found that was the best way to get useful results) is not really economically viable for anyone involved.

Another issue he alluded to is that you still have to read/review the PR yourself to know if the LLM is saying anything that makes the slightest sense; then read through the LLM's (extremely verbose in the case of GPT-5) output and decide for each point it makes if it's worthwhile feedback or a hallucination. Is that worthwhile to catch the extra issues GPT-5 saw compared to his control human-conducted review? Maybe, but it's a lot of extra cognitive load for something a lot of devs already don't love doing. I could definitely see people just taking the LLM output as gospel and failing to properly review the PR themselves, with disastrous results. I'm also interested to know more details about how he did the control review - I know he did it himself but how much time did he spend on it? Did he deliberately write issues into the PR and only expect the LLM to find those, or did he review it after to look for more? The difference between 5 runs for each of ~8 LLMs and one human review of unknown effort/thoroughness strikes me as something a scientific journal might take issue with.

## Links

### [How to remember anything forever-ish](https://ncase.me/remember) - Nicky Case

Spaced repetition is not something I've often used deliberately, since I didn't consider anything taught in school or uni worth remembering until after the last assessment covering it. But Nicky does a great job explaining how & why it works here, so if my kids ever need help studying I'll dig through the archives for this and show them.

### [picsvg](https://picsvg.com/)

I quite often find myself wanting an .svg version of some image I can only find a .jpg of, most recently for the favicon of this site. I tried a bunch of different sites and this was the only onw which didn't just give me back a blank black image, so kudos to whoever made it.

### [A Treatise on AI Chatbots Undermining the Enlightenment](https://maggieappleton.com/ai-enlightenment/) - Maggie Appleton

Maggie makes some excellent points about the amplifying effect LLMs have on our already terrifyingly effective online echo chambers, and offers a handy prompt/settings for anyone not just looking to be told how brilliant and correct they are.

The article seems optimistic about 'harsh' prompts like the one it suggests becoming the default for professional use, which is borne out by similar instructions in the `copilot-instructions.md` across our repos at work, but I'm more worried about the unlikeliness of something like that ever becoming the default for general public usage.

AI companies want money, so they want users, and user, generally speaking, don't like being told they might wrong or having their views challenged. Is this different from people googling leading questions like 'why do vaccines cause autism'? Does moving from Google controlling what information people see to OpenAI controlling the same make a big difference? Maybe not at the moment, but take a look at Grok for a potential extreme.

### [An Interactive Guide to SVG Paths](https://www.joshwcomeau.com/svg/interactive-guide-to-paths/) - Josh Comeau

Another quality article from Josh, this time about the mess of seemingly random characters we all paste into svg files from time to time then forget about. I won't remember all the details and probably won't need to, but much like regex a bit of knowledge can go a long way, at least far enough to let you know if it's worth looking up the info you're missing. The section on arcs is especially useful, including interactive demos and breaking the syntax up into components makes it much easier to understand than just reading a technical spec or looking at image examples.

### [Fluid Typography Generator](https://modern-fluid-typography.vercel.app/)

Handy if you want to set up complex breakpoints for your font-size and want a slick visual aid for all the properties.
